{\rtf1\ansi\ansicpg1252\cocoartf2822
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 (venv) (base) bbb@Nesibes-MacBook-Pro workplace-safety-monitoring % yolo task=detect mode=val \\\
  model=runs/detect/crossval/fold_2_run/weights/best.pt \\\
  data=model/dataset/data.yaml split=test name=fold2_eval\
Ultralytics 8.3.143 \uc0\u55357 \u56960  Python-3.12.7 torch-2.7.0 CPU (Apple M4 Pro)\
Model summary (fused): 72 layers, 3,007,598 parameters, 0 gradients, 8.1 GFLOPs\
val: Fast image access \uc0\u9989  (ping: 0.0\'b10.0 ms, read: 1824.4\'b1444.2 MB/s, size: 49.9 KB)\
val: Scanning /Users/bbb/Projects/swe/workplace-safety-monitoring/model/dataset/labels/test.cache.\
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\uc0\u9608 \u9608 \u9608 \
                   all         82        760      0.887      0.702      0.766      0.472\
               Hardhat         30        110      0.989       0.82      0.915      0.586\
                  Mask         16         28      0.979       0.75      0.756      0.544\
            NO-Hardhat         25         41      0.825      0.576      0.578      0.305\
               NO-Mask         30         79      0.924      0.617      0.772       0.34\
        NO-Safety Vest         36         90      0.921      0.774      0.834      0.525\
                Person         59        174      0.869       0.81      0.863       0.56\
           Safety Cone          8         92      0.831      0.373      0.446      0.204\
           Safety Vest         22         61       0.88      0.845      0.897      0.581\
             Machinery         22         44       0.87      0.818      0.853      0.636\
               Vehicle         15         41      0.786      0.634      0.748      0.437\
Speed: 0.7ms preprocess, 106.6ms inference, 0.0ms loss, 0.4ms postprocess per image\
Results saved to runs/detect/fold2_eval\
\uc0\u55357 \u56481  Learn more at https://docs.ultralytics.com/modes/val\
VS Code: view Ultralytics VS Code Extension \uc0\u9889  at https://docs.ultralytics.com/integrations/vscode\
}